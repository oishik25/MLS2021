# -*- coding: utf-8 -*-
"""CW2604_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TqZzFCNOTeALfeJcOts58hjREEzGeAeD

Step 1
"""

!git clone https://github.com/YoongiKim/CIFAR-10-images

import torch
import numpy as np
from torchvision import datasets
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
import os
import pandas as pd
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

"""Step 2 Activating CUDA"""

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

"""Step 3"""

# convert data to a normalized torch.FloatTensor
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(), # randomly flip and rotate
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

"""Step 4"""

p=[]
c=[]
for file_name in os.listdir("CIFAR-10-images/test/"):
  for files in os.listdir("CIFAR-10-images/test/"+file_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        #img = cv2.imread("CIFAR-10-images/test/airplane/0000.jpg" + file_name)
        #print('CIFAR-10-images/test/'+file_name+'/'+files, file_name)
        #dataset.append([['CIFAR-10-images/test/'+file_name+'/'+files , file_name]])
        path='CIFAR-10-images/test/'+file_name+'/'+files
        cls=file_name
        p.append(path)
        c.append(cls)



data_set=pd.DataFrame({'path':p,'class':c})
data_set.to_csv("test",index=False)

p=[]
c=[]
for file_name in os.listdir("CIFAR-10-images/train/"):
  for files in os.listdir("CIFAR-10-images/train/"+file_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        #img = cv2.imread("CIFAR-10-images/test/airplane/0000.jpg" + file_name)
        #print('CIFAR-10-images/test/'+file_name+'/'+files, file_name)
        #dataset.append([['CIFAR-10-images/test/'+file_name+'/'+files , file_name]])
        path='CIFAR-10-images/train/'+file_name+'/'+files
        cls=file_name
        p.append(path)
        c.append(cls)


data_set1=pd.DataFrame({'path':p,'class':c})
data_set1.to_csv("train",index=False)

def do_your_transform(X):
  class MyDataset(Dataset):
    def __init__(self,image_set,augment=True):
      with open(image_set,"r") as csv.handle:
        csv_reader= csv.reader(csv_handle,delimiter=',')
        self.imgfiles=[eachline[0] for eachline in csv_reader]

      with open(image_set,'r') as csv_handle:
        csv_reader=csv.reader(csv_handle,delimiter=',')
        self.classlabels=[int(eachline[1]) for eachline in csv_reader]

      self.augment=augment

    def __len__(self):
      return len(selg.imgfiles)

    def __getitem__(self,idx):
      img = imageio.imread(self.imgfiles[idx])
      X=np.asarray(img,dtype=np.float32)

      if self.augment:
        X=do_your_transform(X)
      Y=self.classlabels[idx]
      return X,Y



# define the CNN architecture
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # convolutional layer (sees 32x32x3 image tensor)
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        # convolutional layer (sees 16x16x16 tensor)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        # convolutional layer (sees 8x8x32 tensor)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)
        # max pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        # linear layer (64 * 4 * 4 -> 500)
        self.fc1 = nn.Linear(64 * 4 * 4, 500)
        # linear layer (500 -> 10)
        self.fc2 = nn.Linear(500, 10)
        # dropout layer (p=0.25)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        # add sequence of convolutional and max pooling layers
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        # flatten image input
        x = x.view(-1, 64 * 4 * 4)
        # add dropout layer
        x = self.dropout(x)
        # add 1st hidden layer, with relu activation function
        x = F.relu(self.fc1(x))
        # add dropout layer
        x = self.dropout(x)
        # add 2nd hidden layer, with relu activation function
        x = self.fc2(x)
        return x

# create a complete CNN
model = Net()
print(model)

# move tensors to GPU if CUDA is available
if train_on_gpu:
    model.cuda()

# specify loss function (categorical cross-entropy)
criterion = nn.CrossEntropyLoss()

# specify optimizer
optimizer = optim.SGD(model.parameters(), lr=0.01)